{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a133829-d5b7-4067-902f-a2fcc400c91c",
   "metadata": {},
   "source": [
    "Code supporting the article. \n",
    "As the structures of the compounds are not provided, only the morphological profile based classifier can be tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e944204-7af7-4001-a100-7d4a4211be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Draw, MACCSkeys, rdFMCS, MolStandardize\n",
    "from rdkit.Chem.MolStandardize import rdMolStandardize\n",
    "from rdkit.ML.Cluster import Butina\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import recall_score, balanced_accuracy_score, matthews_corrcoef, accuracy_score, precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994ab7f-eaf4-45cd-9a46-c3711662f4e8",
   "metadata": {},
   "source": [
    "# getting acute toxicity label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d881fd-6dfc-438b-8103-5eb7b233a744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we load a csv containging the concensus profiles, the acute toxicity label (Tox60), and the butina clusters\n",
    "cellPainting_consensusMorphologicalProfile_acuteToxicity = pd.read_csv('data/cellPainting_consensusMorphologicalProfile_acuteToxicity.csv')\n",
    "# we also load the set of selected features\n",
    "CaravaggioDalitFeatSeat01 = pd.read_csv('data/CaravaggioDalitFeatSeat01.csv').iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8f8dd-ab03-49f6-8f44-1b616d55399a",
   "metadata": {},
   "source": [
    "# chemical structure based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f028b1-35e9-4d98-ac2e-1e169322aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dataframe containing the smiles\n",
    "smiles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a060d2-7e69-4a9b-baa6-e3f5c4ad307d",
   "metadata": {},
   "source": [
    "## cleaning smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea39ba-aefe-471f-98b1-1f86b8f92f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(smiles):\n",
    "    \"\"\"Standardized the smiles.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles : string\n",
    "        the smiles.\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    string\n",
    "        standardized smiles.\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    # removeHs, disconnect metal atoms, normalize the molecule, reionize the molecule\n",
    "    clean_mol = rdMolStandardize.Cleanup(mol) \n",
    "    # if many fragments, get the \"parent\" (the actual mol we are interested in) \n",
    "    parent_clean_mol = rdMolStandardize.FragmentParent(clean_mol)\n",
    "    # try to neutralize molecule\n",
    "    uncharger = rdMolStandardize.Uncharger() # annoying, but necessary as no convenience method exists\n",
    "    uncharged_parent_clean_mol = uncharger.uncharge(parent_clean_mol)    \n",
    "    te = rdMolStandardize.TautomerEnumerator() # idem\n",
    "    taut_uncharged_parent_clean_mol = te.Canonicalize(uncharged_parent_clean_mol)\n",
    "    return Chem.MolToSmiles(taut_uncharged_parent_clean_mol, isomericSmiles=False)\n",
    "\n",
    "# we call the function to standardized the smiles\n",
    "smiles_df.loc[:, 'standardized_smiles'] = smiles_df.smiles.apply(standardize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd897405-142b-40b4-8d4f-a6b81f801782",
   "metadata": {},
   "source": [
    "## morgan fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ab302-94c4-4255-ab94-c1f72a25210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createChemicalSpace (smiles_df, smilesColumn):\n",
    "    \"\"\"Create Morgan fingerprint features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles_df : pandas dataframe\n",
    "        a dataframe containting a column with smiles.\n",
    "    smilesColumn : string\n",
    "        the name of the column containting the smiles.\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    pandas dataframe\n",
    "        original pandas dataframe with new columns for the Morgan fp features named '0', '1'....\n",
    "    \"\"\"\n",
    "    #we create a df of unique smiles. This df will be used to return the coordinates\n",
    "    res_df = smiles_df.loc[:, smilesColumn].drop_duplicates()\n",
    "    #we get rid of the Nan\n",
    "    res_df = res_df[res_df.notna()]\n",
    "    print('Number of unique compounds in data:', len(res_df.values))\n",
    "\n",
    "    # we transform the smiles into an rdkit object\n",
    "    rdkitObject = [Chem.MolFromSmiles(m) for m in res_df.values]\n",
    "\n",
    "    # we create a list of boolean telling if an object has been created\n",
    "    validRdkitObject = [False if o is None else True for o in rdkitObject]\n",
    "    \n",
    "    # we display the smiles that couldn't be converted into a rdkit object\n",
    "    print (\"Error with those smiles: \")\n",
    "    print(res_df[~np.array(validRdkitObject)])\n",
    "        \n",
    "    # we get rid of the lines where the rdkitObject is None in the dataframe containing the smiles\n",
    "    res_df = res_df[validRdkitObject]\n",
    "    \n",
    "    # now we create the list of valid molecules, meaning the list of rdkitObject that are not None\n",
    "    mols = [o for o in rdkitObject if o is not None ]\n",
    "    #calculate Morgan fingerprints as bit vectors:\n",
    "    fps = [AllChem.GetMorganFingerprintAsBitVect(m,2,1024) for m in mols]\n",
    "    #fpgen = [AllChem.GetRDKitFPGenerator(m), for m in mols]\n",
    "    \n",
    "    #now we get the list of bit vectors\n",
    "    fps_bits = [(np.frombuffer(fp.ToBitString().encode(), 'u1') - ord('0')).tolist() for fp in fps]\n",
    "    fps_bits = pd.DataFrame(fps_bits)\n",
    "    fps_bits = fps_bits.astype(bool)\n",
    "\n",
    "    print('Number of molecules OK in data:', len(mols))\n",
    "    print('Number of Fingerprints in data:', len(fps_bits))\n",
    "    \n",
    "    res_df = pd.concat([res_df.reset_index(drop=True), fps_bits.reset_index(drop=True)], axis=1, sort=False)\n",
    "    return  pd.merge(smiles_df, res_df, on=smilesColumn, how='left')\n",
    "\n",
    "smiles_df = createChemicalSpace(smiles_df, 'standardized_smiles' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287eb372-7cb4-4acb-8b02-717dae38e166",
   "metadata": {},
   "source": [
    "## Butina clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7325c20-54ad-4675-96d4-e02cfc94b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeButinaClusters(smiles_list, cutoff = 0.7)\n",
    "    \"\"\"Create Morgan fingerprint features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    smiles_list : list\n",
    "        a list of smiles.\n",
    "    cutoff : float\n",
    "        the Butina algorithm cutoff value.\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    pandas dataframe\n",
    "       a pandas dataframe with the smiles and the butina cluster number\n",
    "    \"\"\"\n",
    "    mols = []\n",
    "    for smiles in all_smiles:\n",
    "        mols.append(Chem.MolFromSmiles(smiles))\n",
    "    fps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, 1024) for x in mols]\n",
    "    # calcaulate scaffold sets\n",
    "    # first generate the distance matrix:\n",
    "    dists = []\n",
    "    nfps = len(fps)\n",
    "    for i in range(1, nfps):\n",
    "        sims = DataStructs.BulkTanimotoSimilarity(fps[i], fps[:i])\n",
    "        dists.extend([1 - x for x in sims])\n",
    "    scaffold_sets = Butina.ClusterData(dists,\n",
    "                                       nfps,\n",
    "                                       cutoff,\n",
    "                                       isDistData=True,\n",
    "                                      reordering = True)\n",
    "    butinaCluster = pd.DataFrame( index = all_smiles.index, columns = ['cluster']) \n",
    "    for cl in range(len(scaffold_sets)):\n",
    "        for i in scaffold_sets[cl]:\n",
    "            butinaCluster.iloc[i]['cluster'] = cl\n",
    "    return butinaCluster\n",
    "\n",
    "computeButinaClusters(smiles_df.standardized_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3e899-55a5-4652-854c-b655a031036b",
   "metadata": {},
   "source": [
    "## classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d3e8cfa-9feb-4531-bed8-28e1af2d58c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def veryAcuteClassifier (x, y, model, nb_cross_cross_validation = 10, nb_fold = 10, SEED = 24, case_chemistry = 'known', clusters = None):\n",
    "    \"\"\"Run classification models and display average metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array-like\n",
    "        training data.\n",
    "    y : array-like\n",
    "        target values.\n",
    "    model : scikit learn model\n",
    "        classifier model (not fitted).\n",
    "    nb_cross_cross_validation : int\n",
    "        number of X fold cross validation\n",
    "    nb_fold : int\n",
    "        number of fold for the cross validation\n",
    "    SEED : int\n",
    "        random seed to use for the cross validation\n",
    "    case_chemistry : string\n",
    "        'known' for knowwn chemistry case\n",
    "        'new' for new chemistry case\n",
    "    clusters :  array-like\n",
    "        list of clusters for the new chemistry case\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    NONE\n",
    "    \"\"\"\n",
    "\n",
    "    results_df = pd.DataFrame([])\n",
    "\n",
    "    for CrossValIteration in range(nb_cross_cross_validation):\n",
    "\n",
    "        if case_chemistry == 'known':\n",
    "            skf = StratifiedKFold(n_splits=nb_fold, shuffle = True, random_state = SEED + (CrossValIteration*1))\n",
    "\n",
    "            for train, test in skf.split(y, y):\n",
    "                xTrain = x.iloc[train, :]\n",
    "                xTest = x.iloc[test, :]\n",
    "                yTrain = y.iloc[train]\n",
    "                yTest = y.iloc[test]\n",
    "\n",
    "                model.fit(xTrain, yTrain)\n",
    "\n",
    "                yPredicted = model.predict(xTest)\n",
    "\n",
    "                # metric\n",
    "                BA = balanced_accuracy_score(yTest, yPredicted)\n",
    "                MCC = matthews_corrcoef(yTest, yPredicted)\n",
    "                SN = recall_score(yTest, yPredicted)\n",
    "                SP = 2*BA - SN\n",
    "                PR = precision_score(yTest, yPredicted)\n",
    "\n",
    "                results_df = pd.concat( [results_df, pd.DataFrame([[BA, MCC, SN, SP, PR]],\n",
    "                    columns = ['BA', 'MCC', 'SN', 'SP', 'PR'])])\n",
    "\n",
    "        elif case_chemistry == 'new':\n",
    "            sgkf = StratifiedGroupKFold(n_splits=nb_fold, shuffle = True, random_state = SEED + (CrossValIteration*1))\n",
    "\n",
    "            for train, test in sgkf.split(x, y, clusters):\n",
    "                xTrain = x.iloc[train, :]\n",
    "                xTest = x.iloc[test, :]\n",
    "                yTrain = y.iloc[train]\n",
    "                yTest = y.iloc[test]\n",
    "\n",
    "                model.fit(xTrain, yTrain)\n",
    "\n",
    "                yPredicted = model.predict(xTest)\n",
    "\n",
    "                # metric\n",
    "                BA = balanced_accuracy_score(yTest, yPredicted)\n",
    "                MCC = matthews_corrcoef(yTest, yPredicted)\n",
    "                SN = recall_score(yTest, yPredicted)\n",
    "                SP = 2*BA - SN\n",
    "                PR = precision_score(yTest, yPredicted)\n",
    "\n",
    "                results_df = pd.concat( [results_df, pd.DataFrame([[BA, MCC, SN, SP, PR]],\n",
    "                    columns = ['BA', 'MCC', 'SN', 'SP', 'PR'])])\n",
    "\n",
    "    results_df = results_df.query('MCC != 0')\n",
    "    print('BA: '+str(results_df.BA.mean())+ ' +/- ' +str(results_df.BA.std()))\n",
    "    print('MCC: '+str(results_df.MCC.mean())+ ' +/- ' +str(results_df.MCC.std()))\n",
    "    print('SN: '+str(results_df.SN.mean())+ ' +/- ' +str(results_df.SN.std()))\n",
    "    print('SP: '+str(results_df.SP.mean())+ ' +/- ' +str(results_df.SP.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a315a93e-466d-4ef4-a160-4e2e5c7d8c11",
   "metadata": {
    "tags": []
   },
   "source": [
    "### known chemistry case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd51909b-1b74-4ce3-91a5-587eeb2e87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = smiles_df\n",
    "y= smiles_df.Tox60\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', metric = 'jaccard', n_jobs = -1)\n",
    "\n",
    "veryAcuteClassifier (x, y, model, nb_cross_cross_validation = 10, nb_fold = 10, SEED = 24, case_chemistry = 'known')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c954ef25-9169-45d8-9444-4460deba65da",
   "metadata": {},
   "source": [
    "### new chemistry case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cff311-4807-4982-aa87-168b59f882a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = smiles_df\n",
    "y= smiles_df.Tox60\n",
    "butinaCluster = smiles_df.cluster\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', metric = 'jaccard', n_jobs = -1)\n",
    "\n",
    "veryAcuteClassifier (x, y, model, nb_cross_cross_validation = 10, nb_fold = 10, SEED = 24, case_chemistry = 'new', clusters = butinaCluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ad68e-46e4-4ec5-829e-130aebbd3c8c",
   "metadata": {},
   "source": [
    "# morphological profiles based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e35b88-6f00-4180-b9dd-49c269f177f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_singleMorphologicalProfiles_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7399c7c-1596-43ae-945d-ff6880bd65b1",
   "metadata": {},
   "source": [
    "## feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23311506-7eae-46ee-9b11-556968b162fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performed at single profile level (not provided)\n",
    "features = all_singleMorphologicalProfiles_df.loc[:, feature_cols].columns.tolist()\n",
    "metadata = all_singleMorphologicalProfiles_df.drop(feature_cols, axis=\"columns\").columns.tolist()\n",
    "feature_select_opts = [\n",
    "    \"blocklist\",\n",
    "    \"drop_outliers\",\n",
    "    \"variance_threshold\",\n",
    "    \"correlation_threshold\",\n",
    "    \"noise_removal\",\n",
    "]\n",
    "\n",
    "all_data_cleaned = pycytominer.feature_select(\n",
    "    profiles=all_singleMorphologicalProfiles_df, \n",
    "    features=features,\n",
    "    samples=\"all\",\n",
    "    operation=feature_select_opts,\n",
    "    corr_method=\"pearson\",\n",
    "    outlier_cutoff=500,\n",
    "    freq_cut=0.05,\n",
    "    unique_cut=0.01,\n",
    "    corr_threshold=0.9,\n",
    "    noise_removal_perturb_groups = 'Metadata_BCS_conc',\n",
    "    noise_removal_stdev_cutoff = 1.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509fe98-0e8f-4cf7-a46b-78f4af9b0c5d",
   "metadata": {},
   "source": [
    "## classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34da818-8055-405b-8d80-2aaeb3867959",
   "metadata": {
    "tags": []
   },
   "source": [
    "### known chemistry case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2389987e-28db-49d1-ba2f-dc2d56f99410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA: 0.744452096724824 +/- 0.07887693787674932\n",
      "MCC: 0.4995151528371864 +/- 0.15919366782765879\n",
      "SN: 0.7033976124885217 +/- 0.12496304637503236\n",
      "SP: 0.7855065809611265 +/- 0.11830071909464804\n"
     ]
    }
   ],
   "source": [
    "x = cellPainting_consensusMorphologicalProfile_acuteToxicity.query('Metadata_concentration == 31.6').loc[:, CaravaggioDalitFeatSeat01]\n",
    "y= cellPainting_consensusMorphologicalProfile_acuteToxicity.query('Metadata_concentration == 31.6').loc[:, 'Tox60']\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', metric = 'correlation', n_jobs = -1)\n",
    "\n",
    "veryAcuteClassifier (x, y, model, nb_cross_cross_validation = 10, nb_fold = 10, SEED = 24, case_chemistry = 'known')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af977a5f-6290-4ba1-ba67-daac43da9865",
   "metadata": {},
   "source": [
    "### new chemistry case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659de0cd-8a74-4f47-8130-52369bafe84b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BA: 0.7193065207832812 +/- 0.11883594111574444\n",
      "MCC: 0.41765812443150213 +/- 0.22523895833792934\n",
      "SN: 0.6633066363931305 +/- 0.21878613520945045\n",
      "SP: 0.7753064051734322 +/- 0.14730494511774617\n"
     ]
    }
   ],
   "source": [
    "x = cellPainting_consensusMorphologicalProfile_acuteToxicity.query('Metadata_concentration == 31.6').loc[:, CaravaggioDalitFeatSeat01]\n",
    "y= cellPainting_consensusMorphologicalProfile_acuteToxicity.query('Metadata_concentration == 31.6').loc[:, 'Tox60']\n",
    "butinaCluster = cellPainting_consensusMorphologicalProfile_acuteToxicity.query('Metadata_concentration == 31.6').loc[:, 'cluster']\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', metric = 'correlation', n_jobs = -1)\n",
    "\n",
    "veryAcuteClassifier (x, y, model, nb_cross_cross_validation = 10, nb_fold = 10, SEED = 24, case_chemistry = 'new', clusters = butinaCluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156af6a-95d7-46d7-be47-499c9ef88d64",
   "metadata": {},
   "source": [
    "# Decision support model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661298c1-e53d-4bb6-8b27-ad739a2a95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with cell painting morphological profile for 31.6µM, with Morgan Fingerprint, with acute toxicity label, and with butina cluster\n",
    "cellPainting_consensusMorphologicalProfile_MorganFP_acuteToxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "17893607-eac0-404a-ac30-6aa121410e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "class DecisionSupportModel(ClassifierMixin, BaseEstimator):\n",
    "\n",
    "    def __init__(self, clf):\n",
    "        # the two KNN classifiers\n",
    "        self.KNN_CP31 = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', metric = 'correlation', n_jobs = -1)\n",
    "        self.KNN_MFP = KNeighborsClassifier(n_neighbors=1, weights = 'uniform', metric = 'jaccard', n_jobs = -1)\n",
    "        # the decision support classifier\n",
    "        self.clf = clf\n",
    "        # the columns for the cell painting features\n",
    "        self.CPfeatureSet = CaravaggioDalitFeatSeat01\n",
    "        # the columns for the Morgan Fingerprint\n",
    "        self.MFfeatureSet = [str(num) for num in range(1024)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    " \n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "       \n",
    "        # training of the two KNNs\n",
    "        self.KNN_CP31 = self.KNN_CP31.fit(self.X_[self.CPfeatureSet], self.y_)\n",
    "        self.KNN_MFP = self.KNN_MFP.fit(self.X_[self.MFfeatureSet], self.y_)\n",
    "        \n",
    "        # we get the first kneighbor distances for both KNN and we create a df\n",
    "        KNN_res = pd.DataFrame([self.KNN_CP31.kneighbors()[0].ravel(),\n",
    "        self.X_.iloc[self.KNN_CP31.kneighbors()[1].ravel()].Tox60.values,  \n",
    "        self.KNN_MFP.kneighbors()[0].ravel(),\n",
    "        self.X_.iloc[self.KNN_MFP.kneighbors()[1].ravel()].Tox60.values, y]).T\n",
    "        KNN_res.columns = ['d_CP', 'CP_pred', 'd_MFP', 'MFP_pred', 'Tox60']\n",
    "        # subset when predictions of the two KNN do not agree\n",
    "        KNN_res = KNN_res.query('CP_pred != MFP_pred')\n",
    "\n",
    "        # synthetic data\n",
    "        KNN_res_more = KNN_res.copy()\n",
    "        KNN_res_more = KNN_res_more.query('CP_pred == Tox60')\n",
    "        random.seed(1)\n",
    "        # we create synthetic data\n",
    "        KNN_res_more.loc[:, 'd_MFP'] = [random.uniform(0.7, 0.9) for _ in range(KNN_res_more.shape [0])]\n",
    "        # we add them to the training set\n",
    "        KNN_res = pd.concat([KNN_res, KNN_res_more])\n",
    "        \n",
    "        # we fit the decision support classifier with the training set\n",
    "        self.clf = self.clf.fit(KNN_res.iloc[:, :-1], KNN_res.iloc[:, -1])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "  \n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X_', 'y_'])\n",
    "\n",
    "        # df with predictions and distances of the nearest neighbors for the two KNN\n",
    "        KNN_res_test = pd.DataFrame([self.KNN_CP31.kneighbors(X[self.CPfeatureSet])[0].ravel(),\n",
    "        self.KNN_CP31.predict(X[self.CPfeatureSet]),\n",
    "        self.KNN_MFP.kneighbors(X[self.MFfeatureSet])[0].ravel(),\n",
    "        self.KNN_MFP.predict(X[self.MFfeatureSet])]).T\n",
    "        KNN_res_test.columns = ['d_CP', 'CP_pred', 'd_MFP', 'MFP_pred']\n",
    "        \n",
    "        # we create the prediction column which takes per default le Cell Painting KNN prediction\n",
    "        KNN_res_test.loc[:, 'pred'] = KNN_res_test.loc[:, 'CP_pred'].values\n",
    "        \n",
    "\n",
    "        # case when the two KNN do not have the same predicions -> we use the decision support model\n",
    "        if KNN_res_test.loc[KNN_res_test.CP_pred != KNN_res_test.MFP_pred, 'pred'].shape[0] > 0:\n",
    "            KNN_res_test.loc[KNN_res_test.CP_pred != KNN_res_test.MFP_pred, 'pred'] = self.clf.predict(KNN_res_test.loc[KNN_res_test.CP_pred != KNN_res_test.MFP_pred, ['d_CP', 'CP_pred', 'd_MFP', 'MFP_pred']])\n",
    "        # we return the predictions\n",
    "        return KNN_res_test.loc[:, 'pred'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24079e98-a12c-4f23-86c4-3877f248c37e",
   "metadata": {},
   "source": [
    "## known chemistry case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0535a45-dd9e-4468-b6ef-7289d5e5f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cellPainting_consensusMorphologicalProfile_MorganFP_acuteToxicity\n",
    "y= cellPainting_consensusMorphologicalProfile_MorganFP_acuteToxicity.Tox60\n",
    "\n",
    "model = DecisionSupportModel((clf = SVC(C = 8, class_weight = 'balanced')))\n",
    "\n",
    "veryAcuteClassifier (x, y, model, nb_cross_cross_validation = 10, nb_fold = 10, SEED = 24, case_chemistry = 'new', clusters = butinaCluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da27035-c9b9-4184-80d1-82238b57a5a4",
   "metadata": {},
   "source": [
    "## new chemistry case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb63f02-b408-4207-bc51-6ab55fc11bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cellPainting_consensusMorphologicalProfile_MorganFP_acuteToxicity\n",
    "y= cellPainting_consensusMorphologicalProfile_MorganFP_acuteToxicity.Tox60\n",
    "butinaCluster = cellPainting_consensusMorphologicalProfile_MorganFP_acuteToxicity.cluster\n",
    "\n",
    "model = DecisionSupportModel((clf = SVC(C = 8, class_weight = 'balanced')))\n",
    "\n",
    "veryAcuteClassifier (x, y, model, nb_cross_cross_validation = 10, nb_fold = 10, SEED = 24, case_chemistry = 'new', clusters = butinaCluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db44fbc-c368-4232-bb73-7b799e6e7d0c",
   "metadata": {},
   "source": [
    "# statistical test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b27bb-a01a-425b-86d1-61691593cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_stats.html\n",
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "def corrected_std(differences, n_train, n_test):\n",
    "    \"\"\"Corrects standard deviation using Nadeau and Bengio's approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    differences : ndarray of shape (n_samples,)\n",
    "        Vector containing the differences in the score metrics of two models.\n",
    "    n_train : int\n",
    "        Number of samples in the training set.\n",
    "    n_test : int\n",
    "        Number of samples in the testing set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    corrected_std : float\n",
    "        Variance-corrected standard deviation of the set of differences.\n",
    "    \"\"\"\n",
    "    # kr = k times r, r times repeated k-fold crossvalidation,\n",
    "    # kr equals the number of times the model was evaluated\n",
    "    kr = len(differences)\n",
    "    corrected_var = np.var(differences, ddof=1) * (1 / kr + n_test / n_train)\n",
    "    corrected_std = np.sqrt(corrected_var)\n",
    "    return corrected_std\n",
    "\n",
    "\n",
    "def compute_corrected_ttest(differences, df, n_train, n_test):\n",
    "    \"\"\"Computes right-tailed paired t-test with corrected variance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    differences : array-like of shape (n_samples,)\n",
    "        Vector containing the differences in the score metrics of two models.\n",
    "    df : int\n",
    "        Degrees of freedom.\n",
    "    n_train : int\n",
    "        Number of samples in the training set.\n",
    "    n_test : int\n",
    "        Number of samples in the testing set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    t_stat : float\n",
    "        Variance-corrected t-statistic.\n",
    "    p_val : float\n",
    "        Variance-corrected p-value.\n",
    "    \"\"\"\n",
    "    mean = np.mean(differences)\n",
    "    std = corrected_std(differences, n_train, n_test)\n",
    "    t_stat = mean / std\n",
    "    p_val = t.sf(np.abs(t_stat), df)  # right-tailed t-test\n",
    "    return t_stat, p_val\n",
    "\n",
    "model_1_scores = model_scores.iloc[0].values  # scores of the best model\n",
    "model_2_scores = model_scores.iloc[1].values  # scores of the second-best model\n",
    "\n",
    "differences = model_1_scores - model_2_scores\n",
    "\n",
    "n = differences.shape[0]  # number of test sets\n",
    "df = n - 1\n",
    "n_train = len(list(cv.split(X, y))[0][0])\n",
    "n_test = len(list(cv.split(X, y))[0][1])\n",
    "\n",
    "t_stat, p_val = compute_corrected_ttest(differences, df, n_train, n_test)\n",
    "print(f\"Corrected t-value: {t_stat:.3f}\\nCorrected p-value: {p_val:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fab",
   "language": "python",
   "name": "conda_fab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
